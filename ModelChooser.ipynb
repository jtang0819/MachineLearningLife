{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BestModel(Data):\n",
    "       \n",
    "    def DTC(Data):\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        # Importing the dataset\n",
    "        dataset = Data\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Training the Decision Tree Classification model on the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score\n",
    "        \n",
    "    def RFC(Data):\n",
    "        # Random Forest Classification\n",
    "        # Importing the libraries\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        # Importing the dataset\n",
    "        dataset = Data\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Training the Random Forest Classification model on the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score\n",
    "    \n",
    "    def SVM(Data):\n",
    "        # Support Vector Machine (SVM)\n",
    "        # Importing the libraries\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        # Importing the dataset\n",
    "        dataset = Data\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Training the SVM model on the Training set\n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score\n",
    "\n",
    "    def KNN(Data):\n",
    "        # K-Nearest Neighbors (K-NN)\n",
    "        # Importing the libraries\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        # Importing the dataset\n",
    "        dataset = Data\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Training the K-NN model on the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score    \n",
    "    \n",
    "    def KSVM(Data):\n",
    "        # Kernel SVM\n",
    "\n",
    "        # Importing the libraries\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        # Importing the dataset\n",
    "        dataset = Data\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Training the Kernel SVM model on the Training set\n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score    \n",
    "    \n",
    "    def LOGR(Data):\n",
    "        # Logistic Regression\n",
    "        # Importing the libraries\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        # Importing the dataset\n",
    "        dataset = Data\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Training the Logistic Regression model on the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score\n",
    "\n",
    "    def NAIVE(Data):\n",
    "        # Naive Bayes\n",
    "\n",
    "        # Importing the libraries\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        # Importing the dataset\n",
    "        dataset = Data\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Training the Naive Bayes model on the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        return score\n",
    "    \n",
    "    matrix = [\n",
    "        [\"Decision Tree Classifier\", DTC(Data)],\n",
    "        ['Random Forest Classifier', RFC(Data)],\n",
    "        ['Support Vector Machine', SVM(Data)],\n",
    "        ['K-NN Model', KNN(Data)],\n",
    "        ['K-SVM Model', KSVM(Data)],\n",
    "        ['Logistic Regression Model', LOGR(Data)],\n",
    "        ['Naive Bayes Model', NAIVE(Data)]\n",
    "    ]\n",
    "    \n",
    "    best = []\n",
    "    accuracy = 0\n",
    "\n",
    "    for i in matrix:\n",
    "        if i[-1] > accuracy:\n",
    "            best = [i]\n",
    "            accuracy = i[-1]\n",
    "        elif i[-1] == accuracy:\n",
    "            best.append(i)\n",
    "\n",
    "    names = [n[0] for n in best]\n",
    "    accuracy = best[0][1]\n",
    "    \n",
    "    conclusion = f\"The Best Model is the {names} with a accuracy of {accuracy}\"\n",
    "    return conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug Data Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Model is the ['Decision Tree Classifier'] with a accuracy of 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Data = pd.read_csv('Data.csv')\n",
    "print(BestModel(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Model is the ['Support Vector Machine', 'Naive Bayes Model'] with a accuracy of 7\n"
     ]
    }
   ],
   "source": [
    "matrix = [\n",
    "        [\"Decision Tree Classifier\", 1],\n",
    "        ['Random Forest Classifier', 2],\n",
    "        ['Support Vector Machine', 7],\n",
    "        ['K-NN Model', 4],\n",
    "        ['K-SVM Model', 5],\n",
    "        ['Logistic Regression Model', 6],\n",
    "        ['Naive Bayes Model', 7]\n",
    "    ]\n",
    "\n",
    "best = []\n",
    "accuracy = 0\n",
    "\n",
    "for i in matrix:\n",
    "    if i[-1] > accuracy:\n",
    "        best = [i]\n",
    "        accuracy = i[-1]\n",
    "    elif i[-1] == accuracy:\n",
    "        best.append(i)\n",
    "            \n",
    "names = [n[0] for n in best]\n",
    "accuracy = best[0][1]\n",
    "conclusion = f\"The Best Model is the {names} with a accuracy of {accuracy}\"\n",
    "print(conclusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
